{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMlmUXmmT5hpe0Pr4+B98iu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kNFYLtwgGrtR"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV, validation_curve\n","from sklearn.impute import SimpleImputer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.feature_selection import mutual_info_classif, SelectKBest\n","from sklearn.metrics import accuracy_score\n","from google.colab import drive\n","import matplotlib.pyplot as plt\n","\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","\n","# Load the data\n","train1 = pd.read_csv('/content/drive/My Drive/training1.csv')\n","train2 = pd.read_csv('/content/drive/My Drive/training2.csv')\n","test = pd.read_csv('/content/drive/My Drive/test.csv')\n","\n","# Combine training datasets\n","train = pd.concat([train1, train2], ignore_index=True)\n","\n","# Separate features and labels\n","X = train.drop(['label', 'confidence'], axis=1)\n","y = train['label']\n","confidence = train['confidence']\n","\n","# Define CNN and Gist feature columns\n","cnn_features = X.columns[:3072]\n","gist_features = X.columns[3072:]\n","\n","# Split the data into training and validation sets\n","X_train, X_val, y_train, y_val, confidence_train, confidence_val = train_test_split(X, y, confidence, test_size=0.2, random_state=42)\n","\n","# Data imputation\n","imputer = SimpleImputer(strategy='mean')\n","X_train = imputer.fit_transform(X_train)\n","X_val = imputer.transform(X_val)\n","test = imputer.transform(test)\n","\n","# Data scaling\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_val = scaler.transform(X_val)\n","test = scaler.transform(test)\n","\n","# Separate CNN and Gist features in training and validation sets\n","X_train_cnn = X_train[:, :3072]\n","X_train_gist = X_train[:, 3072:]\n","X_val_cnn = X_val[:, :3072]\n","X_val_gist = X_val[:, 3072:]\n","test_cnn = test[:, :3072]\n","test_gist = test[:, 3072:]\n","\n","# Feature selection using mutual information\n","mi_selector_cnn = SelectKBest(mutual_info_classif, k=50).fit(X_train_cnn, y_train)\n","X_train_cnn_selected = mi_selector_cnn.transform(X_train_cnn)\n","X_val_cnn_selected = mi_selector_cnn.transform(X_val_cnn)\n","test_cnn_selected = mi_selector_cnn.transform(test_cnn)\n","\n","mi_selector_gist = SelectKBest(mutual_info_classif, k=50).fit(X_train_gist, y_train)\n","X_train_gist_selected = mi_selector_gist.transform(X_train_gist)\n","X_val_gist_selected = mi_selector_gist.transform(X_val_gist)\n","test_gist_selected = mi_selector_gist.transform(test_gist)\n","\n","# Combine selected features\n","X_train_selected = np.hstack((X_train_cnn_selected, X_train_gist_selected))\n","X_val_selected = np.hstack((X_val_cnn_selected, X_val_gist_selected))\n","test_selected = np.hstack((test_cnn_selected, test_gist_selected))\n","\n","# Use a smaller subset for hyperparameter tuning\n","X_train_tune, _, y_train_tune, _, confidence_train_tune, _ = train_test_split(X_train_selected, y_train, confidence_train, train_size=0.2, random_state=42)\n","\n","# Hyperparameter tuning for GradientBoostingClassifier using RandomizedSearchCV\n","param_dist_gb = {\n","    'n_estimators': [100, 150],\n","    'learning_rate': [0.05, 0.1],\n","    'max_depth': [3, 4],\n","    'subsample': [0.8, 0.9],\n","    'min_samples_split': [2, 4],\n","    'min_samples_leaf': [1, 2]\n","}\n","gb = GradientBoostingClassifier()\n","gb_cv = RandomizedSearchCV(gb, param_dist_gb, n_iter=5, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n","gb_cv.fit(X_train_tune, y_train_tune)\n","best_gb = gb_cv.best_estimator_\n","\n","# Hyperparameter tuning for RandomForestClassifier using RandomizedSearchCV\n","param_dist_rf = {\n","    'n_estimators': [100, 150],\n","    'max_features': ['sqrt'],\n","    'max_depth': [10, 15],\n","    'min_samples_split': [2, 4],\n","    'min_samples_leaf': [1, 2]\n","}\n","rf = RandomForestClassifier()\n","rf_cv = RandomizedSearchCV(rf, param_dist_rf, n_iter=5, cv=3, scoring='accuracy', n_jobs=-1, random_state=42)\n","rf_cv.fit(X_train_tune, y_train_tune)\n","best_rf = rf_cv.best_estimator_\n","\n","# Validation curve for Gradient Boosting\n","param_range = np.arange(10, 101, 20)\n","train_scores, test_scores = validation_curve(\n","    GradientBoostingClassifier(),\n","    X_train_selected, y_train,\n","    param_name=\"n_estimators\",\n","    param_range=param_range,\n","    cv=3,\n","    scoring=\"accuracy\",\n","    n_jobs=-1\n",")\n","\n","train_scores_mean = np.mean(train_scores, axis=1)\n","test_scores_mean = np.mean(test_scores, axis=1)\n","\n","plt.figure()\n","plt.plot(param_range, train_scores_mean, label=\"Training score\", color=\"r\")\n","plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\", color=\"g\")\n","plt.title(\"Validation Curve with Gradient Boosting\")\n","plt.xlabel(\"Number of Estimators\")\n","plt.ylabel(\"Accuracy\")\n","plt.tight_layout()\n","plt.legend(loc=\"best\")\n","plt.show()\n","\n","# Performance for different training sets\n","training_sizes = [0.1, 0.2, 0.5, 0.8]\n","rf_accuracies = []\n","gb_accuracies = []\n","\n","for size in training_sizes:\n","    X_train_sub, _, y_train_sub, _, confidence_sub, _ = train_test_split(X_train_selected, y_train, confidence_train, train_size=size, random_state=42)\n","\n","    best_rf.fit(X_train_sub, y_train_sub)\n","    best_gb.fit(X_train_sub, y_train_sub)\n","\n","    rf_pred = best_rf.predict(X_val_selected)\n","    gb_pred = best_gb.predict(X_val_selected)\n","\n","    rf_accuracies.append(accuracy_score(y_val, rf_pred))\n","    gb_accuracies.append(accuracy_score(y_val, gb_pred))\n","\n","plt.figure()\n","plt.plot(training_sizes, rf_accuracies, label=\"Random Forest\", marker='o')\n","plt.plot(training_sizes, gb_accuracies, label=\"Gradient Boosting\", marker='o')\n","plt.xlabel('Training Set Size (fraction)')\n","plt.ylabel('Validation Accuracy')\n","plt.title('Validation Accuracy vs Training Set Size')\n","plt.legend(loc='best')\n","plt.tight_layout()\n","plt.show()\n","\n","# Effect of label confidence\n","# Train models with and without confidence weights\n","best_rf.fit(X_train_selected, y_train)\n","best_rf_weighted = RandomForestClassifier(**rf_cv.best_params_)\n","best_rf_weighted.fit(X_train_selected, y_train, sample_weight=confidence_train)\n","\n","best_gb.fit(X_train_selected, y_train)\n","best_gb_weighted = GradientBoostingClassifier(**gb_cv.best_params_)\n","best_gb_weighted.fit(X_train_selected, y_train, sample_weight=confidence_train)\n","\n","rf_pred = best_rf.predict(X_val_selected)\n","rf_weighted_pred = best_rf_weighted.predict(X_val_selected)\n","gb_pred = best_gb.predict(X_val_selected)\n","gb_weighted_pred = best_gb_weighted.predict(X_val_selected)\n","\n","print(f\"Random Forest Accuracy (without confidence): {accuracy_score(y_val, rf_pred)}\")\n","print(f\"Random Forest Accuracy (with confidence): {accuracy_score(y_val, rf_weighted_pred)}\")\n","print(f\"Gradient Boosting Accuracy (without confidence): {accuracy_score(y_val, gb_pred)}\")\n","print(f\"Gradient Boosting Accuracy (with confidence): {accuracy_score(y_val, gb_weighted_pred)}\")\n","\n","# Save these results into a table\n","results = pd.DataFrame({\n","    'Model': ['Random Forest', 'Random Forest Weighted', 'Gradient Boosting', 'Gradient Boosting Weighted'],\n","    'Accuracy': [\n","        accuracy_score(y_val, rf_pred),\n","        accuracy_score(y_val, rf_weighted_pred),\n","        accuracy_score(y_val, gb_pred),\n","        accuracy_score(y_val, gb_weighted_pred)\n","    ]\n","})\n","\n","# Make predictions on the test set\n","test_predictions = best_rf.predict(test_selected)\n","\n","# Save predictions in the required format\n","predictions_df = pd.DataFrame(test_predictions, columns=['prediction'])\n","predictions_df.to_csv('/content/drive/My Drive/predictions.csv', index=False)\n"]}]}